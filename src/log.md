[<img width=900 src="https://raw.githubusercontent.com/txt/mase/master/img/banner1.png">](https://github.com/txt/mase/blob/master/README.md)   
[At a glance...](https://github.com/txt/mase/blob/master/OVERVIEW.md) |
[Syllabus](https://github.com/txt/mase/blob/master/SYLLABUS.md) |
[Models](https://github.com/txt/mase/blob/master/MODELS.md) |
[Code](https://github.com/txt/mase/tree/master/src) |
[Lecturer](http://menzies.us) 


<a href="log.py"><img align=right src="https://raw.githubusercontent.com/txt/mase/master/img/py.png"></a>

Logs are places to store records of past events. There are two types of logs:

+ _Num_ : for numbers
+ _Sym_ : for everything else. 

Those logs can be queried to find e.g. the highest
and lowest value of the number seen so far. Alternatively,
they can be queried to return values at the same probability
as the current log contents.

### Max Log Size

To avoid logs consuming all memory, logs store at
most _The.cache.keep_ entries (e.g. 128):

+ If more
than that number of entries arrive, then some old
entry (selected at random) will be deleted.
+ The nature of this cache means that some rare
events might be missed. To check for that, running
the code multiple times and, each time, double the
cache size. Stop when doubling the cache size stops
changing the output.

Just as an example of that process, here we are logging 1,000,000 numbers in a log with a cache of size 16.
Note that the resulting cache is much smaller than 1,000,000 items. Also, the contents of the cache
come from the entire range one to one million (so our log is not biased to just the first few samples:

     % python -i log.py
     >>> The.cache.keep = 16
     >>> log = Num()  
     >>> for x in xrange(1000000): log += x 
     >>> sorted(log._cache)
     [77748, 114712, 122521, 224268, 
     289880, 313675, 502464, 625036, 
     661881, 663207, 680085, 684674, 
     867075, 875594, 922141, 945896]
     >>> 

### Caching Slow Reports

Some of the things we want to report from these logs take a little while to calculate (e.g. finding the median
requires a sort of a numeric cache):

+ Such reports should be run and cached so they can be accessed many time without the need
for tedious recalculation. 
+ These reports become outdated if new log information arrives so the following
code deletes these reports if ever new data arrives.
+ The protocol for access those reports is to call _log.has().x_ where "x" is a field
  generated by the report.  Log subclasses generate reports using the special _report()_ method
  (see examples, below).

Just as an example of reporting, after the above run (where we logged 1,000,000 numbers), the following reports are available:

     >>> log.has().lo
     0 
     >>> log.has().hi
     945896
     >>> print log.has().median # 50th percentile
     662544.0
     >>> print log.has().iqr # (75-25)th percentile
     205194

Note that our median is not as expected (it should be around half a million). Why? Well, clearly a cache of size 16 is
too small to track a million numbers. So how many numbers do we need? Well, that depends on the distribution being explored
but here's how the median is effected by cache size for uniform distributions:

    >>> for size in [16,32,64,128,256]:
    ...     The.cache.keep=size
    ...     log = Num()
    ...     for x in xrange(1000000): log += x
    ...     print size, ":" log.has().median
    ... 
     16 : 637374.5
     32 : 480145.5
     64 : 520585.5
    128 : 490742.0
    256 : 470870.5


Note that we get pretty close to half a million with cache sizes at 32 or above. And the lesson: sometimes, a limited
sample can offer a useful approximation to a seemingly complex process.

## Standard Header
````python
   1:   from __future__ import division
   2:   import sys, random, math, datetime, time,re
   3:   sys.dont_write_bytecode = True
   4:   from base  import *
   5:   from stats import *
   6:   from a12 import *
````
<a href="log.py#L88-L93"><img align=right src="http://www.craiggiven.com/textfile_icon.gif"></a>
## Classes

### Base Class: "Log"

````python
   7:   class Log():
   8:     "Keep a random sample of stuff seen so far."
   9:     def __init__(i,inits=[],label=''):
  10:       i.label = label
  11:       i._cache,i.n,i._report = [],0,None
  12:       i.setup()
  13:       map(i.__iadd__,inits)
  14:     def __iadd__(i,x): #  magic method for "+="
  15:       if x == None: return x # skip nothing
  16:       i.n += 1
  17:       changed = False
  18:       if len(i._cache) < The.cache.keep: # not full
  19:         changed = True
  20:         i._cache += [x]               # then add
  21:       else: # otherwise, maybe replace an old item
  22:         if rand() <= The.cache.keep/i.n:
  23:           changed = True
  24:           i._cache[int(rand()*The.cache.keep)] = x
  25:       if changed:      
  26:         i._report = None # wipe out 'what follows'
  27:         i.change(x)
  28:       return i
  29:     def any(i):  
  30:       return  any(i._cache)
  31:     def has(i):
  32:       if i._report == None: i._report =  i.report()
  33:       return i._report
  34:     def setup(i): pass
  35:     def change(i,x): pass
````
<a href="log.py#L100-L128"><img align=right src="http://www.craiggiven.com/textfile_icon.gif"></a>

### Num

A _Num_ is a _Log_ for numbers. 

+ Tracks _lo_ and _hi_ values. 
+ Reports median and the IQR the (75-25)th range.
+ Generates numbers from the log by a three-way interpolation (see _ish()_).


````python
  36:   class Num(Log):
  37:     def setup(i):
  38:       i.lo, i.hi = 10**32, -10**32
  39:       i.lessp = True
  40:     def change(i,x): # update lo,hi
  41:       i.lo = min(i.lo, x)
  42:       i.hi = max(i.hi, x)
  43:     def norm(i,x): # turn "x" into 0..1
  44:       return (x - i.lo)/(i.hi - i.lo + 0.000001)
  45:     def ordered():
  46:       i.has()
  47:       return i._cache
  48:     def report(i): 
  49:       lst = i._cache = sorted(i._cache)
  50:       n   = len(lst)     
  51:       return o(
  52:         median= i.median(),
  53:         iqr   = lst[int(n*.75)] - lst[int(n*.5)],
  54:         lo    = i.lo, 
  55:         hi    = i.hi)
  56:     def ish(i,f=0.1): # return a num from  logged dist 
  57:       return i.any() + f*(i.any() - i.any())
  58:     def better(new,old):
  59:       "better if (1)less median or (2)same and less iqr"
  60:       t = The.misc.a12
  61:       betterIqr = new.has().iqr < old.has().iqr
  62:       if new.lessp:
  63:         betterMed = new.has().median >= old.has().median
  64:         same      = a12(old._cache, new._cache)  <= t
  65:       else:
  66:         betterMed = new.has().median <= old.has().median 
  67:         same      = a12(new._cache, old._cache) <= t
  68:       return betterMed, same, betterIqr
  69:     def median(i):
  70:       n = len(i._cache)
  71:       p = n // 2
  72:       if (n % 2):  return i._cache[p]
  73:       q = p + 1
  74:       q = max(0,(min(q,n)))
  75:       return (i._cache[p] + i._cache[q])/2
  76:   
  77:   def _num():
  78:     i = Num([rand()      for _ in xrange(1000)])
  79:     j = Num([rand()*1.25 for _ in xrange(1000)])
  80:     print j.same(i)
  81:   
````
<a href="log.py#L141-L186"><img align=right src="http://www.craiggiven.com/textfile_icon.gif"></a>

WARNING: the call to _sorted_ in _report()_ makes this code
a candidate for a massive CPU suck (it is always sorting newly arrived data).
So distinguish between _adding_ things to a log in the _last_ era and 
using that information in the _next_ era (so the log from the last era
is staple in the current).

### Sym

A _Sym_ is a _Log_ for non-numerics.

+ Tracks frequency counts for symbols, and the most common symbol (the _mode_);
+ Reports the entropy of the space (a measure of diversity: lower values mean fewer rarer symbols);
+ Generated symbols from the log by returning symbols at the same probability of the frequency counts (see _ish()_).

````python
  82:   class Sym(Log):
  83:     def setup(i):
  84:       i.counts,i.mode,i.most={},None,0
  85:     def report(i):
  86:       for x in i._cache:
  87:         c = i.counts[x] = i.counts.get(x,0) + 1
  88:         if c > i.most:
  89:           i.mode,i.most = x,c
  90:       return o(dist= i.dist(), 
  91:                 ent = i.entropy(),
  92:                 mode= i.mode)
  93:     def dist(i):
  94:       d = i.counts
  95:       n = sum(d.values())
  96:       return sorted([(d[k]/n, k) for k in d.keys()], 
  97:                     reverse=True)
  98:     def ish(i):
  99:       r,tmp = rand(),0
 100:       for w,x in i.has().dist:
 101:         tmp  += w
 102:         if tmp >= r: 
 103:           return x
 104:       return x
 105:     def entropy(i,e=0):
 106:       for k in i.counts:
 107:         p = i.counts[k]/len(i._cache)
 108:         e -= p*log2(p) if p else 0
 109:       return e    
````
<a href="log.py#L204-L231"><img align=right src="http://www.craiggiven.com/textfile_icon.gif"></a>

#### Sym, Example

As an example of generating numbers from a distribution, consider the following code.
The logged population has plus, grapes and pears in the ration 2:1:1.
From that population, we can generate another distribution that is nearly the same:

    >>> symDemo()
    (0.5, 'plums'), (0.265625, 'grapes'), (0.234375, 'pears')]
    {'plums': 64, 'grapes': 34, 'pears': 30}

````python
 110:   def symDemo(n1=10,n2=1000):
 111:     rseed()
 112:     log= Sym((['plums']*(n1*2)) + ['grapes']*n1 + ['pears']*n1)
 113:     found= Sym([log.ish() for _ in xrange(n2)])
 114:     print found.has().dist
 115:     print found.counts
 116:     print sum(found.counts.values())
 117:   
 118:   if __name__ == "__main__": eval(cmd()) 
 119:   
 120:   
````


_________

<img align=right src="https://raw.githubusercontent.com/txt/mase/master/img/pd-icon.png">Copyright Â© 2015 [Tim Menzies](http://menzies.us).
This is free and unencumbered software released into the public domain.   
For more details, see the [license](https://github.com/txt/mase/blob/master/LICENSE.md).

