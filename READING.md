[<img width=900 src="https://raw.githubusercontent.com/txt/mase/master/img/banner1.png">](https://github.com/txt/mase/blob/master/README.md)   
[At a glance...](https://github.com/txt/mase/blob/master/OVERVIEW.md) |
[Syllabus](https://github.com/txt/mase/blob/master/SYLLABUS.md) |
[Models](https://github.com/txt/mase/blob/master/MODELS.md) |
[Code](https://github.com/txt/mase/tree/master/src) |
[Lecturer](http://menzies.us) 


# Read123456789: reading research papers

<img src="img/dogreading.jpg" align=right>

As technologies change, technologists need to
continually update their technical knowledge.
The problem with that is that reading all the latest research is very hard.
Working through complex technical papers is a complex and technical task.
For example, if you ask new graduate students to read ten papers in a particular sub-field:

+ It can take a full day to read the first paper.
+ But after reading ten papers, they can do it much faster.

## How to Read Papers, Faster

There are two keys to reading papers faster:

+ _Context:_ Experts can read papers faster when they know of other work in the field and can place this new
paper into the context of other work. 
+ _Feature extraction:_  Experts are experts at anything since they know what to look for, and what can be skipped over. This is true for many tasks, including reading:
    + Experts do not read entire papers, word for word.
    + Rather, they hunt and peek looking for [certain key features](READINGrubric.md).


<img src="img/sboard.png" width=400 align=right>
To put that another way,  papers are not read for _repeatability_ (of the whole paper) but for _reusability_ of their parts. 
Technical papers are really a
  presentation of [many connected technical concepts](READINGrubric.md),
some of which the reader will extract and apply to their own work.
So  we should not read papers so we can paint them again as beautiful complete works of art.
Rather, we should treat them as a design of some complex product...

+ Which can be exploded into [various parts](READINGrubric.md)...
+ ... any of which might be repurposed in other areas.

To put that another way, we should not _read_ papers but we should _survey_ them, to

+ Map out their [internal structure](READINGrubric.md)
+ To find and extract whatever [parts](READINGrubric.md) might be useful to use.

Of course, once we find the (little) bits that we really want to use, then we might spend hours/days struggling
to understand those (small) parts. But otherwise, we need to read _over_ papers, not _through_ them. 

## Exercises In Reading Faster

Note that, at first, it will take _hours_ to read one paper. However, after a couple your reading will speed
up dramatically. So do not be discouraged if, at first, this is ridiculously slow.

### Part1 (nine small tasks)

In the following, anything shown _in italics_ is explained below.

+ Week1: Find a highly cited paper from the automated software engineering literature
     + Go  [here](https://goo.gl/HqOVJ1)
     + Pick any 2011 paper and _summarize some of its parts_.
+ Week2,3,4,5: Walk backwards
     + Find four papers in the week1's reference list
          + That date 2008 to 2010
	      + That are _highest cited_ (Note that recent papers have less cites than older papers).
	  + Walk them backwards in time, one per week, _summarizing some of there parts_
+ Week6,7,8: Walk forwards
      + Find four papers that cite the week1 paper
          + That date 2012 to 2015
	      + That are _highly cited_ (Note that recent papers have less cites than older papers)..
      + Walk them forwards in time, one per week, _summarizing some of there parts_
+ Week9: For any paper in the above sequence, _report any reusable data_.

Notes:

+ By _summarize parts_ we mean write 500 to 1000 words  on text:
    + Starting with  a clear reference to the paper
    + Followed by brief notes on any half dozen of the items listed  [here](READINGrubric.md).
    + For weeks2,3,4,5,6,7,8 also comment on the connection to the other papers.
    + Do you know how long 1000 words is? About as long as this page. How you
  want to write something half this size.
+ To find _highest cited papers_, look up items from the reference list in the week1 paper paper in scholar.google.com (or dl.acm.org/ or
  ieeexplore.ieee.org) and count their citations.  For example, looking up
  "Mining metrics to predict component failures" in scholar.google.com produces:<br>
  <img src="img/cite1.png" width=500><br>
  Looking bottom, you can see _Cited by 527_. If you click there, you find many others published since the first paper:<br>
  <img src="img/cite2.png" width=500 ><br>
  Google scholar sorts these top-to-bottom most-to-least cited (so the most cited papers are shown at top). So,
+ To find the _highest cited papers_ that cite the week1 paper, look up your week1 paper in scholar.google.com (or dl.acm.org/ or
  ieeexplore.ieee.org) and count their citations.
+ To _report any reusable data_, try to fill in the form [here](http://openscience.us/repo/contribute/donate). Hand in either:
      - A page shown what you entered from those fields
       - Or an explanation why your kind of papers do not generated data of the kind that can be entered here.

### Part2 (one big essay)

Take all the above and summarize the procession of research 2008 to 2015 of some automated software
engineering issue.

+ 10 pages, 2 columns,  using the Word or Latex formats shown in [this page](https://www.acm.org/sigs/publications/proceedings-templates).
+ Include at least 18 references, nine of which are the nine shown above
+ Mention as many as possible of items listed [here]READINGrubric.md).

For full marks,

+ Through out your text,
       comment on how eight of these nine papers improved (failed to improve, ignored, extended, refined) the issues
       mentioned in an early paper.
+ End with your own recommendations of the path from here. Mention the issues that are now retired, that no one has retired,
	     that someone should retire, or that no one should even try to retire.

Note: if your Part1 nine papers proved to be dull, fell free to start again with some other 2011 paper from
[here](https://goo.gl/HqOVJ1).



_________

<img align=right src="https://raw.githubusercontent.com/txt/mase/master/img/pd-icon.png">Copyright Â© 2015 [Tim Menzies](http://menzies.us).
This is free and unencumbered software released into the public domain.   
For more details, see the [license](https://github.com/txt/mase/blob/master/LICENSE.md).

